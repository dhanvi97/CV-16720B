{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490fbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b59c9cbe",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"figures/course.png\" width=\"800\">\n",
    "\n",
    "#                                    16720 (B) Neural Networks for Recognition - Assignment 3\n",
    "\n",
    "     Instructor: Kris Kitani                       TAs: Arka, Jinkun, Rawal, Rohan, Sheng-Yu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1265a1",
   "metadata": {},
   "source": [
    "## Q3 Extract Text from Images (35 points, write-up)\n",
    "\n",
    "**Please include all the answers to the write-up questions to HW3:PDF**. \n",
    "![](figures/annotatedLetters.jpg)\n",
    "<center>Sample image with handwritten characters annotated with boxes around each character</center>\n",
    "\n",
    "Now that you have a network that can recognize handwritten letters with reasonable accuracy, you can now use it to parse text in an image. Given an image with some text on it, our goal is to have a function that returns the actual text in the image. However, since your neural network expects a a binary image with a single character, you will need to process the input image to extract each character. There are various approaches that can be done so feel free to use any strategy you like.\n",
    "\n",
    "Here we outline one possible method, another is that given in a [tutorial](http://scikit-image.org/docs/dev/auto_examples/segmentation/plot_label.html)\n",
    "1. Process the image ([blur](http://scikit-image.org/docs/dev/auto_examples/filters/plot_denoise.html), [threshold](http://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.try_all_threshold), [opening morphology](http://scikit-image.org/docs/dev/api/skimage.morphology.html#skimage.morphology.opening), etc. (perhaps in that order)) to classify all pixels as being part of a character or background.\n",
    "2. Find connected groups of character pixels (see [skimage.measure.label](http://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.label)). Place a bounding box around each connected component.\n",
    "3. Group the letters based on which line of the text they are a part of, and sort each group so that the letters are in the order they appear on the page.\n",
    "4. Take each bounding box one at a time and resize it to $32\\times 32$, classify it with your network, and report the characters in order (inserting spaces when it makes sense).\n",
    "\n",
    "Since the network you trained likely does not have perfect accuracy, you can expect there to be some errors in your final text parsing. Whichever method you choose to implement for the character detection, you should be able to place a box on most of there characters in the image. We have provided you with **01\\_list.jpg**, **02\\_letters.jpg**, **03\\_haiku.jpg** and **04\\_deep.jpg** to test your implementation on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aada939",
   "metadata": {},
   "source": [
    "### Q3.1 (3 points, write-up)\n",
    "The method outlined above is pretty simplistic, and makes several assumptions. What are two big assumptions that the sample method makes. In your writeup, include two example images where you expect the character detection to fail (either miss valid letters, or respond to non-letters).\n",
    "\n",
    "<font color=\"red\">**Please include your answer to HW3:PDF**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f0bd5",
   "metadata": {},
   "source": [
    "### Q3.2 (13 points, write-up + code)\n",
    "Find letters in the image. Given an RGB image, this function should return bounding boxes for all of the located handwritten characters in the image, as well as a binary black-and-white version of the image \\texttt{im}. Each row of the matrix should contain **[y1,x1,y2,x2]** the positions of the top-left and bottom-right corners of the box. The black and white image should be floating point, 0 to 1, with the characters in black and background in white. \n",
    "\n",
    "<font color=\"red\">**Please include your answer to HW3:PDF**</font>\n",
    "\n",
    "<font color=\"red\">**For this question, please also submit screenshot of your code snippets to the write-up**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68170446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.color\n",
    "import skimage.restoration\n",
    "import skimage.io\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "import skimage.segmentation\n",
    "\n",
    "# takes a color image\n",
    "# returns a list of bounding boxes and black_and_white image\n",
    "def findLetters(image):\n",
    "    bboxes = []\n",
    "    bw = None\n",
    "    # insert processing in here\n",
    "    # one idea estimate noise -> denoise -> greyscale -> threshold -> morphology -> label -> skip small boxes \n",
    "    # this can be 10 to 15 lines of code using skimage functions\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return bboxes, bw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec946318",
   "metadata": {},
   "source": [
    "### Q3.3 (6 points, write-up + code)\n",
    "Run `findLetters()` on all of the provided sample images in **images/**. Plot all of the located boxes on top of the image to show the accuracy of your `findLetters()` function. Include all the result images in your writeup.\n",
    "\n",
    "<font color=\"red\">**Please include your answer to HW3:PDF**</font>\n",
    "\n",
    "<font color=\"red\">**For this question, please also submit screenshot of your code snippets to the write-up**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b03ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "\n",
    "from ipynb.fs.defs.q1 import *\n",
    "\n",
    "# do not include any more libraries here!\n",
    "# no opencv, no sklearn, etc!\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "for img in os.listdir('images'):\n",
    "    im1 = skimage.img_as_float(skimage.io.imread(os.path.join('images',img)))\n",
    "    bboxes, bw = findLetters(im1)\n",
    "\n",
    "    plt.imshow(bw)\n",
    "    for bbox in bboxes:\n",
    "        minr, minc, maxr, maxc = bbox\n",
    "        rect = matplotlib.patches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                                fill=False, edgecolor='red', linewidth=2)\n",
    "        plt.gca().add_patch(rect)\n",
    "    plt.show()\n",
    "    # find the rows using..RANSAC, counting, clustering, etc.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # crop the bounding boxes\n",
    "    # note.. before you flatten, transpose the image (that's how the dataset is!)\n",
    "    # consider doing a square crop, and even using np.pad() to get your images looking more like the dataset\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d988128",
   "metadata": {},
   "source": [
    "### Q3.4 (13 points, write-up + code)\n",
    "Now you will load the image, find the character locations, classify each one with the network you trained in **Q2.1**, and return the text contained in the image. Be sure you try to make your detected images look like the images from the training set. Visualize them and act accordingly. \n",
    "\n",
    "<font color=\"red\">**Please include your answer to HW3:PDF**</font>\n",
    "\n",
    "<font color=\"red\">**For this question, please also submit screenshot of your code snippets to the write-up**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6298f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights\n",
    "# run the crops through your neural network and print them out\n",
    "import pickle\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "letters = np.array([_ for _ in string.ascii_uppercase[:26]] + [str(_) for _ in range(10)])\n",
    "params = pickle.load(open('q2_weights.pickle','rb'))\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
